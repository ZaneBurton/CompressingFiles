# CompressingFilesDesign: 

The design I originally started doing, was making different classes for each potential command line call. I had unintentionally misheard the client and thought he wanted that. Thus I had to redo half the project and combine all of my Deschub functions. Like I said I had originally had created them in each of their own classes. This led to a fairly easy to read SchubsH and SchubsL classes. I simply treat all of the text files that are going to be compressed as string arrays and simply use that string array to hold the paths of each file and pass that string array through a loop that then compresses each file. I believe I did almost the exact same style for the LZW algorithm as well. I feel like should be ways to definitely shorten the Huffman algorithm. Possibly not care so much about the trie, but I understand that reading the trie can be fairly quick but personally I have to read so that seems like a lose lose situation for me.

# CompressingFilesTestingAndInstructions:

Testing & Instructions: You are going to start off with an already built project. I noticed when trying to push everything to Github the best way to do it was with my project already built. So there will be no need for you to run an “mvn build.” Thus you can jump right into some command line instructions. You may start by attempting to call ShubsL src/resources/*txt. This will use the LZW algorithm to compress all of the text files that are located in the resources folder. Then to check your work you may then proceed to Deschubs src/compressed/*.ll. This will expand all of the .ll files in the compressed folder and expand them inside the decompressed folder. Then you may run SchubsH src/resources/*.txt and you will see all of the .hh compressed files inside of the compressed folder. Again you may want to check and see if you have the correct compressed files so you may expand them by calling Deschubs src/compression/*.hh. This will expand all of the .hh files and send them over to the Decompressed folder. If you would like to Tar the files you should be informed that I have somehow integrated Tarring and Untarring to work simultaneously, if you were to call SchubsArc archive.zh, I am unsure how, but I have managed to both Tar the files as well as Untar them. So you might notice that the .zh folder has zero bytes, well that is because it has also been untarred. Now, the command line instructions can get a little bit tricky, you are not going to want to call a Deschubs when you have accidentally deleted the compressed files, or already expanded them. So be careful when attempting to make a call on something that is not possible. Examples include, trying to expand a file that is missing, already been expaned, or a file that is not expandable. Please also refrain from attempting to compress files that have already been compressed, or that are missing.
You might be wondering what the mvn build does, well for starters the actual command tests for each class that we are using for the CLI. For example, I wrote a test file and some functions for each of the SchubsL, SchubsH, Deschubs, and SchubsArc. In these tests I tried my best to simulate what a command line argument would be and thus when I passed the tests I knew that my classes were sufficient. Thus when you start with mvn test, it goes through every test I wrote that is checking each of the classes. It will Tar and Untar compressed files, it will compress files, expand files, it is essentially acting as the first user of the program.

Thus you have now completed the README, instruction manual, and spiritual journey.
